# Application Workflow: File-to-File Interactions

This document explains the complete workflow of the application, from startup to request handling.

---

## ðŸš€ Part 1: Server Startup Flow

```
1. npm run dev
   â””â”€> Executes: nodemon server.js

2. server.js (Main Entry Point)
   â”œâ”€> Line 1-7: Import all dependencies
   â”‚   â”œâ”€â”€ express
   â”‚   â”œâ”€â”€ morgan (logger)
   â”‚   â”œâ”€â”€ swagger-ui-express
   â”‚   â”œâ”€â”€ ./src/config/db (Database connection)
   â”‚   â”œâ”€â”€ ./src/routes/userRoutes
   â”‚   â”œâ”€â”€ ./src/routes/analyticsRoutes
   â”‚   â””â”€â”€ ./src/config/swagger (API documentation)
   â”‚
   â”œâ”€> Line 10-11: Initialize Express app
   â”‚
   â”œâ”€> Line 14-15: Setup Middleware
   â”‚   â”œâ”€â”€ morgan('dev') - Logs every HTTP request
   â”‚   â””â”€â”€ express.json() - Parses JSON request bodies
   â”‚
   â”œâ”€> Line 18: Mount Swagger UI at /api-docs
   â”‚
   â”œâ”€> Line 21-22: Register Route Handlers
   â”‚   â”œâ”€â”€ /users â†’ userRoutes
   â”‚   â””â”€â”€ /analytics â†’ analyticsRoutes
   â”‚
   â””â”€> Line 27-34: startServer() function
       â”œâ”€â”€ Calls connectDB() from src/config/db.js
       â”œâ”€â”€ Calls connectRedis() from src/config/redis.js
       â””â”€â”€ Starts listening on port 3000
```

---

## ðŸ”Œ Part 2: Database Connection (src/config/db.js)

```javascript
// FILE: src/config/db.js

connectDB() is called from server.js
â”‚
â”œâ”€> Line 8-11: Connect to MongoDB
â”‚   â””â”€â”€ mongodb://localhost:27017/taskManagerDB
â”‚
â”œâ”€> Line 14-24: Seed Users Collection
â”‚   â”œâ”€â”€ Check if users collection is empty
â”‚   â”œâ”€â”€ If empty, generate 50 mock users
â”‚   â””â”€â”€ Insert into database
â”‚
â””â”€> Line 26-27: Seed Products & Orders
    â””â”€â”€ Calls seedDatabase(db) â†’ src/config/seedData.js
```

### Data Seeding Flow (src/config/seedData.js)

```javascript
// FILE: src/config/seedData.js

seedDatabase(db) receives db instance
â”‚
â”œâ”€> Line 66-81: Seed Products
â”‚   â”œâ”€â”€ Check if products collection is empty
â”‚   â”œâ”€â”€ generateProducts() creates 100 products
â”‚   â””â”€â”€ Insert into database
â”‚
â””â”€> Line 84-104: Seed Orders
    â”œâ”€â”€ Check if orders collection is empty
    â”œâ”€â”€ Fetch existing userIds from database
    â”œâ”€â”€ Fetch existing productIds from database
    â”œâ”€â”€ generateOrders(userIds, productIds) creates 500 orders
    â””â”€â”€ Insert into database
```

---

## âš¡ Part 3: Redis Connection (src/config/redis.js)

```javascript
// FILE: src/config/redis.js

connectRedis() is called from server.js
â”‚
â”œâ”€> Line 3-5: Create Redis client
â”‚   â””â”€â”€ redis://localhost:6379
â”‚
â”œâ”€> Line 7-8: Setup error & connection event handlers
â”‚
â””â”€> Line 11: Connect to Redis
```

---

## ðŸ“¡ Part 4: HTTP Request Flow (Example: GET /users)

### Step-by-Step Journey of a Request:

```
1. Browser/Postman â†’ GET http://localhost:3000/users?page=1&limit=10
   â”‚
   â”œâ”€> server.js (Line 14) - morgan middleware logs the request
   â”œâ”€> server.js (Line 15) - express.json() parses body (not needed for GET)
   â”‚
   â””â”€> server.js (Line 21) - Routes to userRoutes
       â”‚
       â””â”€> src/routes/userRoutes.js
           â”‚
           â”œâ”€> Line 63: Matches GET /users
           â”‚   â””â”€â”€ router.get('/', userController.getUsers)
           â”‚
           â””â”€> Calls getUsers() in src/controllers/userController.js
               â”‚
               â””â”€> src/controllers/userController.js
                   â”‚
                   â”œâ”€> Line 5: Function getUsers(req, res)
                   â”‚
                   â”œâ”€> Line 7-9: Extract pagination parameters
                   â”‚   â”œâ”€â”€ page = req.query.page || 1
                   â”‚   â””â”€â”€ limit = req.query.limit || 10
                   â”‚
                   â”œâ”€> Line 12: Build cache key: "users:1:10"
                   â”‚
                   â”œâ”€> Line 15-18: CHECK REDIS CACHE
                   â”‚   â”œâ”€â”€ redisClient.get(cacheKey)
                   â”‚   â”œâ”€â”€ If found â†’ Return cached data (âš¡ Fast!)
                   â”‚   â””â”€â”€ If not found â†’ Continue to database
                   â”‚
                   â”œâ”€> Line 21-22: GET DATABASE CONNECTION
                   â”‚   â””â”€â”€ getDb() from src/config/db.js
                   â”‚
                   â”œâ”€> Line 25-28: QUERY MONGODB
                   â”‚   â”œâ”€â”€ usersCollection.find().skip(skip).limit(limit)
                   â”‚   â””â”€â”€ Count total documents (for pagination meta)
                   â”‚
                   â”œâ”€> Line 30-37: BUILD RESPONSE
                   â”‚   â”œâ”€â”€ meta: { total_items, current_page, etc. }
                   â”‚   â””â”€â”€ data: [users array]
                   â”‚
                   â”œâ”€> Line 40: CACHE THE RESULT in Redis (60 seconds)
                   â”‚   â””â”€â”€ redisClient.setEx(cacheKey, 60, JSON.stringify(response))
                   â”‚
                   â””â”€> Line 42: SEND RESPONSE to client
                       â””â”€â”€ res.json(response)
```

---

## ðŸ“Š Part 5: Aggregation Request Flow (Example: GET /analytics/top-products)

```
1. Client â†’ GET http://localhost:3000/analytics/top-products?limit=5
   â”‚
   â””â”€> server.js (Line 22) â†’ Routes to analyticsRoutes
       â”‚
       â””â”€> src/routes/analyticsRoutes.js
           â”‚
           â”œâ”€> Line 38: Matches GET /top-products
           â”‚   â””â”€â”€ router.get('/top-products', analyticsController.getTopProducts)
           â”‚
           â””â”€> Calls getTopProducts() in src/controllers/analyticsController.js
               â”‚
               â””â”€> src/controllers/analyticsController.js
                   â”‚
                   â”œâ”€> Line 52: Function getTopProducts(req, res)
                   â”‚
                   â”œâ”€> Line 54: Extract limit parameter
                   â”‚
                   â”œâ”€> Line 57-61: CHECK REDIS CACHE
                   â”‚   â””â”€â”€ cacheKey = "analytics:top-products:5"
                   â”‚
                   â”œâ”€> Line 66: Get database connection
                   â”‚
                   â”œâ”€> Line 70-112: BUILD AGGREGATION PIPELINE
                   â”‚   â”œâ”€â”€ Stage 1: $match - Filter delivered orders
                   â”‚   â”œâ”€â”€ Stage 2: $unwind - Flatten items array
                   â”‚   â”œâ”€â”€ Stage 3: $group - Sum quantities by product
                   â”‚   â”œâ”€â”€ Stage 4: $sort - Order by quantity sold
                   â”‚   â”œâ”€â”€ Stage 5: $limit - Top 5 products
                   â”‚   â”œâ”€â”€ Stage 6: $lookup - JOIN with products collection
                   â”‚   â”œâ”€â”€ Stage 7: $unwind - Flatten product data
                   â”‚   â””â”€â”€ Stage 8: $project - Format output fields
                   â”‚
                   â”œâ”€> Line 114: EXECUTE PIPELINE
                   â”‚   â””â”€â”€ ordersCollection.aggregate(pipeline).toArray()
                   â”‚
                   â”œâ”€> Line 116: CACHE RESULT (5 minutes)
                   â”‚
                   â””â”€> Line 118: SEND RESPONSE
```

---

## ðŸ”„ Part 6: Data Mutation Flow (Example: POST /users)

```
1. Client â†’ POST http://localhost:3000/users
   Body: { "name": "John", "email": "john@test.com" }
   â”‚
   â””â”€> server.js
       â”œâ”€> morgan logs request
       â”œâ”€> express.json() PARSES BODY into req.body
       â”‚
       â””â”€> userRoutes â†’ userController.createUser()
           â”‚
           â”œâ”€> Line 79-82: Extract data from req.body
           â”‚   â””â”€â”€ const { name, email, role } = req.body
           â”‚
           â”œâ”€> Line 84-86: VALIDATE required fields
           â”‚   â””â”€â”€ If missing, return 400 error
           â”‚
           â”œâ”€> Line 88-93: CREATE user object
           â”‚   â””â”€â”€ Add createdAt timestamp
           â”‚
           â”œâ”€> Line 95: INSERT into MongoDB
           â”‚   â””â”€â”€ usersCollection.insertOne(newUser)
           â”‚
           â”œâ”€> Line 97-100: RETURN success response
           â”‚   â””â”€â”€ Status 201 (Created)
           â”‚
           â””â”€> NOTE: Cache invalidation
               â””â”€â”€ Lists aren't invalidated (rely on 60s TTL)
```

---

## ðŸ”„ Part 7: Cache Invalidation Flow (Example: PUT /users/:id)

```
1. Client â†’ PUT http://localhost:3000/users/65abc123...
   â”‚
   â””â”€> userController.updateUser()
       â”‚
       â”œâ”€> Line 121: Validate ObjectId format
       â”‚
       â”œâ”€> Line 126-129: UPDATE in MongoDB
       â”‚   â””â”€â”€ usersCollection.updateOne({ _id }, { $set: {...} })
       â”‚
       â”œâ”€> Line 136: INVALIDATE specific user cache
       â”‚   â””â”€â”€ redisClient.del(`user:65abc123...`)
       â”‚       â””â”€â”€ Next GET for this user will be cache miss
       â”‚
       â””â”€> Line 138: Return success
```

---

## ðŸ§µ Part 8: Queue & Worker Flow (RabbitMQ version)

```
1. Client â†’ GET http://localhost:3000/analytics/heavy-task?limit=1000000
   â”‚
   â””â”€> analyticsRoutes â†’ analyticsController.getHeavyComputation()
       â”‚
       â”œâ”€> Line 333: Call addJob()
       â”‚   â””â”€â”€ src/config/queue.js
       â”‚
       â”œâ”€> Inside addJob():
       â”‚   â”œâ”€â”€ Generate UUID
       â”‚   â”œâ”€â”€ Save status to Redis: SET job:<uuid> { state: 'active' }
       â”‚   â””â”€â”€ Send msg to RabbitMQ: "heavy-computation" queue
       â”‚
       â””â”€> Line 338: Return Job ID immediately (Non-blocking)
           â””â”€â”€ res.json({ jobId, status: 'started' })

2. BACKGROUND PROCESSING (src/config/queue.js)
   â”‚
   â””â”€> startWorker() (Listening to RabbitMQ)
       â”‚
       â”œâ”€> Message Received! ðŸ“¨
       â”‚
       â”œâ”€> Line 67: Spawn Worker Thread
       â”‚   â””â”€â”€ new Worker('./workers/heavyTaskWorker.js')
       â”‚
       â”œâ”€> Worker Thread (Parallel CPU Core)
       â”‚   â””â”€â”€ Calculates Primes ðŸ”¢
       â”‚
       â””â”€> Worker Finishes
           â”œâ”€â”€ Update Redis: SET job:<uuid> { state: 'completed', result }
           â””â”€â”€ ACK RabbitMQ: Delete message from queue

3. Client â†’ GET http://localhost:3000/analytics/task-status/1
   â”‚
   â””â”€> analyticsController.getTaskStatus()
       â”‚
       â””â”€> READ Redis: GET job:<uuid>
           â”‚
           â”œâ”€> If state="active" â†’ Return "Processing..."
           â””â”€> If state="completed" â†’ Return Result
```

---

## ðŸ—‚ï¸ Complete File Dependency Tree

```
server.js (Root)
â”œâ”€â”€ src/config/db.js
â”‚   â”œâ”€â”€ mongodb (npm package)
â”‚   â””â”€â”€ src/config/seedData.js
â”‚       â””â”€â”€ (generates mock data, no dependencies)
â”‚
â”œâ”€â”€ src/config/redis.js
â”‚   â””â”€â”€ redis (npm package)
â”‚
â”œâ”€â”€ src/config/queue.js
â”‚   â”œâ”€â”€ amqplib (RabbitMQ client)
â”‚   â”œâ”€â”€ uuid (Job ID generation)
â”‚   â”œâ”€â”€ redisClient (State management)
â”‚   â””â”€â”€ src/workers/heavyTaskWorker.js (Worker Thread)
â”‚
â”œâ”€â”€ src/config/swagger.js
â”‚   â”œâ”€â”€ swagger-jsdoc (npm package)
â”‚   â””â”€â”€ reads JSDoc from src/routes/*.js
â”‚
â”œâ”€â”€ src/routes/userRoutes.js
â”‚   â”œâ”€â”€ express.Router()
â”‚   â””â”€â”€ src/controllers/userController.js
â”‚       â”œâ”€â”€ src/config/db.js â†’ getDb()
â”‚       â””â”€â”€ src/config/redis.js â†’ client
â”‚
â””â”€â”€ src/routes/analyticsRoutes.js
    â”œâ”€â”€ express.Router()
    â””â”€â”€ src/controllers/analyticsController.js
        â”œâ”€â”€ src/config/db.js â†’ getDb()
        â”œâ”€â”€ src/config/redis.js â†’ client
        â””â”€â”€ src/config/queue.js â†’ heavyTaskQueue
```

---

## ðŸŽ¯ Key Design Patterns Used

### 1. **MVC Pattern (Sort of)**
```
Routes (src/routes/) â†’ Define URL endpoints
Controllers (src/controllers/) â†’ Business logic
Models â†’ Implicit (MongoDB collections)
```

### 2. **Singleton Pattern**
```javascript
// db.js exports a single db instance
let db; // Shared across all requests
```

### 3. **Middleware Chain**
```javascript
Request â†’ morgan â†’ express.json() â†’ router â†’ controller â†’ response
```

### 4. **Dependency Injection**
```javascript
// db.js doesn't import seedData
// server.js coordinates both
connectDB() â†’ seedDatabase(db) // Passes db instance
```

### 5. **Caching Strategy**
```
Read: Check Cache â†’ Cache Miss â†’ Database â†’ Cache Result â†’ Respond
Write: Update Database â†’ Invalidate Cache
```

### 6. **Job Queue Pattern**
```
Client Request â†’ Add to Queue â†’ Return ID
Background Worker â†’ Process Job â†’ Store Result
Client Polls â†’ Get Result
```

---

## ðŸ“ Summary: How It All Works

1. **Startup**: server.js orchestrates connections (MongoDB, Redis)
2. **Data Seeding**: Automated on first run (users, products, orders)
3. **Request Routing**: Express matches URL â†’ routes â†’ controller
4. **Cache Layer**: Redis stores frequent queries for speed
5. **Database**: MongoDB stores persistent data
6. **Aggregations**: Complex pipeline queries for analytics
7. **Job Queue**: Bull queue manages background jobs
8. **Multi-threading**: Worker threads execute heavy tasks off-main-thread
9. **Response**: JSON data sent back to client

**Flow Diagram (High Level)**:
```
Client Request
    â†“
Morgan Logger
    â†“
JSON Parser
    â†“
Route Matcher (userRoutes/analyticsRoutes)
    â†“
Controller (userController/analyticsController)
    â†“
Redis Cache Check
    â†“ (cache miss)
MongoDB Query OR Add to Queue (Async)
    â†“
Cache Result / Return Job ID
    â†“
JSON Response â†’ Client
```


---

## ðŸ—ï¸ Part 9: Deployment Workflow (Kubernetes)

This is how the application runs in a production-like environment (Kubernetes).

```
1. Build Process
   Dockerfile â†’ docker build â†’ Docker Image (node-app:latest)

2. Deployment (kubectl apply -f k8s/)
   â”‚
   â”œâ”€> Database & Services Start First
   â”‚   â”œâ”€â”€ MongoDB Pod (Port 27017)
   â”‚   â”œâ”€â”€ Redis Pod (Port 6379)
   â”‚   â””â”€â”€ RabbitMQ Pod (Ports 5672/15672)
   â”‚
   â””â”€> Application Starts (node-app Deployment)
       â”‚
       â”œâ”€> Kubernetes injects Environment Variables
       â”‚   â”œâ”€â”€ MONGO_URI from k8s Service DNS (mongodb)
       â”‚   â”œâ”€â”€ REDIS_URL from k8s Service DNS (redis)
       â”‚   â””â”€â”€ RABBITMQ_URL from k8s Service DNS (rabbitmq)
       â”‚
       â””â”€> Application Connects
           â”œâ”€â”€ Connects to mongodb:27017
           â”œâ”€â”€ Connects to redis:6379
           â””â”€â”€ Connects to rabbitmq:5672

3. Traffic Flow
   User (localhost:3000)
    â†“
   Kubernetes Service (LoadBalancer/NodePort)
    â†“
   Node App Pod
    â†“
   Internal Cluster DNS (e.g., "mongodb")
    â†“
   Database Pod
```

This architecture allows the application to be scalable, self-healing, and easily managed.

